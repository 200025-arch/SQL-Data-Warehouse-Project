# Sql Data Warehouse Project
Construire un entrepÃ´t de donnÃ©es moderne avec SQL Server, incluant un processus ETL, modÃ©lisation des donnÃ©es et analyses.

Bienvenue dans le dÃ©pÃ´t du projet Data Warehouse  ! ğŸš€
Ce projet prÃ©sente une solution complÃ¨te dâ€™entreposage de donnÃ©es et dâ€™analyse, allant de la construction dâ€™un data warehouse Ã  la production dâ€™insights exploitables. il met en avant les meilleures pratiques du secteur en ingÃ©nierie des donnÃ©es et en analyse de donnÃ©es.

----
## Architecture DATA

Lâ€™architecture des donnÃ©es de ce projet suit le modÃ¨le Medallion avec les couches Bronze, Silver et Gold :

<img width="1133" height="583" alt="Image" src="https://github.com/user-attachments/assets/58fa2415-a31e-4039-a231-45b702f4eda8" />

1.**Couche Bronze** : Stocke les donnÃ©es brutes telles quâ€™elles proviennent des systÃ¨mes sources. Les donnÃ©es sont ingÃ©rÃ©es Ã  partir de fichiers CSV dans une base de donnÃ©es SQL Server.

2.**Couche Silver** : Cette couche inclut les processus de nettoyage, de standardisation et de normalisation des donnÃ©es afin de les prÃ©parer pour lâ€™analyse.

3.**Couche Gold** : Contient les donnÃ©es prÃªtes pour lâ€™entreprise, modÃ©lisÃ©es sous forme de schÃ©ma en Ã©toile, nÃ©cessaires pour les rapports et lâ€™analytique.

----
ğŸ“– **AperÃ§u du projet**

Ce projet comprend :

1.**Architecture des donnÃ©es** : Conception dâ€™un entrepÃ´t de donnÃ©es moderne en utilisant lâ€™architecture Medallion avec les couches Bronze, Silver et Gold.

2.**Pipelines ETL** : Extraction, transformation et chargement des donnÃ©es depuis les systÃ¨mes sources vers lâ€™entrepÃ´t.

3.**ModÃ©lisation des donnÃ©es** : DÃ©veloppement de tables de faits et de dimensions optimisÃ©es pour les requÃªtes analytiques.

4.**Analytique & Reporting** : CrÃ©ation de rapports et tableaux de bord basÃ©s sur SQL pour fournir des insights exploitables.

----
## ğŸš€ PrÃ©requis du projet

**Objectif**
DÃ©velopper un entrepÃ´t de donnÃ©es en utilisant SQL Server afin de consolider les donnÃ©es de ventes, permettant la crÃ©ation de rapports analytiques et la prise de dÃ©cisions Ã©clairÃ©es.

**SpÃ©cifications**
**Sources de donnÃ©es** : Importer les donnÃ©es Ã  partir de deux systÃ¨mes sources (ERP et CRM) fournis sous forme de fichiers CSV.

**QualitÃ© des donnÃ©es** : Nettoyer et rÃ©soudre les problÃ¨mes de qualitÃ© des donnÃ©es avant lâ€™analyse.

**IntÃ©gration** : Combiner les deux sources dans un modÃ¨le de donnÃ©es unique et convivial, conÃ§u pour les requÃªtes analytiques.

**PÃ©rimÃ¨tre** : Se concentrer uniquement sur le jeu de donnÃ©es le plus rÃ©cent ; lâ€™historisation des donnÃ©es nâ€™est pas requise.

**Documentation** : Fournir une documentation claire du modÃ¨le de donnÃ©es pour soutenir Ã  la fois les parties prenantes mÃ©tier et les Ã©quipes analytiques.

----
## BI : Analytique & Reporting (Data Analysis)

**Objectif**
DÃ©velopper des analyses basÃ©es sur SQL afin de fournir des insights dÃ©taillÃ©s sur :

* **Comportement des clients**

* **Performance des produits**

* **Tendances des ventes**

----
## Flux de donnÃ©es 

Le **flux de donnÃ©es** dans cette architecture reprÃ©sente le chemin que suivent les donnÃ©es depuis les systÃ¨mes sources jusquâ€™aux couches finales du modÃ¨le.

<img width="1127" height="536" alt="Image" src="https://github.com/user-attachments/assets/6f8080a3-0f0f-431b-b2e6-348fcadc34be" />

----
## IntÃ©gration des donnÃ©es
Lâ€™intÃ©gration dans une architecture de donnÃ©es consiste Ã  fusionner et harmoniser les informations provenant de plusieurs systÃ¨mes sources afin de crÃ©er une vue unifiÃ©e et cohÃ©rente pour lâ€™analyse.

âœ… **Objectif de lâ€™intÃ©gration :**

* Relier les donnÃ©es des deux systÃ¨mes pour obtenir une vision complÃ¨te.

* Enrichir les dimensions (produits et clients) avec des attributs supplÃ©mentaires provenant de lâ€™ERP.

* PrÃ©parer un modÃ¨le analytique optimisÃ© pour le reporting et la BI.

<img width="1035" height="507" alt="Image" src="https://github.com/user-attachments/assets/c0aa12f6-2502-4fd2-ac8b-985f88ae9d43" />


